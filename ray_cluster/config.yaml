# An unique identifier for the head node and workers of this cluster.
cluster_name: avillalba-dev-ray-cluster
# Cloud-provider specific configuration.
provider:
  type: aws
  region: us-east-1
# The maximum number of workers nodes to launch in addition to the head
# node.
max_workers: 3
# This executes all commands on all nodes in the docker container,
# and opens all the necessary ports to support the Ray cluster.
# Empty string means disabled.
docker:
  image: "879381254630.dkr.ecr.us-east-1.amazonaws.com/poc-multi-instance-data-prep/poc-multi-instance-data-prep-dev-image:latest"
  container_name: "ray-dev-container"
  # If true, pulls latest version of image. Otherwise, `docker run` will only pull the image
  # if no cached version is present.
  pull_before_run: True
# auth:
#   ssh_user: ubuntu
#   ssh_private_key: ~/.ssh/avillalba-key-pair.pem  # make sure chmod 400 <your private key>

# Tell the autoscaler the allowed node types and the resources they provide.
# The key is the name of the node type, which is for debugging purposes.
# The node config specifies the launch config and physical instance type.
available_node_types:
  ray.head.default:
    # The node type's CPU and GPU resources are auto-detected based on AWS instance type.
    # If desired, you can override the autodetected CPU and GPU resources advertised to the autoscaler.
    # You can also set custom resources.
    # For example, to mark a node type as having 1 CPU, 1 GPU, and 5 units of a resource called "custom", set
    # resources: {"CPU": 1, "GPU": 1, "custom": 5}
    resources: {}
    # Provider-specific config for this node type, e.g., instance type. By default
    # Ray auto-configures unspecified fields such as SubnetId and KeyName.
    # For more documentation on available fields, see
    # http://boto3.readthedocs.io/en/latest/reference/services/ec2.html#EC2.ServiceResource.create_instances
    node_config:
      InstanceType: m5.2xlarge
      #KeyName: avillalba-key-pair
      IamInstanceProfile:
        Name: AmazonSageMaker-ExecutionRole-20241203T102031
  ray.worker.default:
    # The minimum number of worker nodes of this type to launch.
    # This number should be >= 0.
    min_workers: 0
    # The maximum number of worker nodes of this type to launch.
    # This parameter takes precedence over min_workers.
    max_workers: 3
    # The node type's CPU and GPU resources are auto-detected based on AWS instance type.
    # If desired, you can override the autodetected CPU and GPU resources advertised to the autoscaler.
    # You can also set custom resources.
    # For example, to mark a node type as having 1 CPU, 1 GPU, and 5 units of a resource called "custom", set
    # resources: {"CPU": 1, "GPU": 1, "custom": 5}
    resources: {}
    # Provider-specific config for this node type, e.g., instance type. By default
    # Ray auto-configures unspecified fields such as SubnetId and KeyName.
    # For more documentation on available fields, see
    # http://boto3.readthedocs.io/en/latest/reference/services/ec2.html#EC2.ServiceResource.create_instances
    node_config:
      InstanceType: m5.2xlarge
      #KeyName: avillalba-key-pair
      IamInstanceProfile:
        Name: AmazonSageMaker-ExecutionRole-20241203T102031
      # InstanceMarketOptions:
      #   MarketType: spot

# # Files or directories to copy to the head and worker nodes. The format is a
# # dictionary from REMOTE_PATH: LOCAL_PATH, e.g.
# file_mounts:
#   "/home/ec2-user/poc-multi-instance-data-prep": "."
