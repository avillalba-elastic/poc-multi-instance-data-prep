{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connect to ElasticSearch Serverless project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to provide a few examples on how to interact with an ElasticSearch Serverless project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "from elasticsearch_serverless import Elasticsearch\n",
    "\n",
    "# add here any package you need to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connection Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created manually a serverless project. This process can also be automated by using the [Project Management REST API](https://www.elastic.co/guide/en/serverless/current/general-manage-project-with-api.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELASTICSEARCH_ENDPOINT = \"https://ml-rd-ops-e3b5cc.es.us-east-1.aws.elastic.cloud:443\"\n",
    "API_KEY = os.environ[\n",
    "    \"ES_SERVERLESS_API_KEY\"\n",
    "]  # you will need to set this environment variable with your API Key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticSearch Serverless client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the [ElasticSearch Python client](https://www.elastic.co/guide/en/serverless/current/elasticsearch-python-client-getting-started.html) whenever possible. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'name': 'serverless', 'cluster_name': 'b876c513c5134470bee831f9762f9f2c', 'cluster_uuid': 'u5yIcSZ3Q6WRX8LdQ83MWw', 'version': {'number': '8.11.0', 'build_flavor': 'serverless', 'build_type': 'docker', 'build_hash': '00000000', 'build_date': '2023-10-31', 'build_snapshot': False, 'lucene_version': '9.7.0', 'minimum_wire_compatibility_version': '8.11.0', 'minimum_index_compatibility_version': '8.11.0'}, 'tagline': 'You Know, for Search'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = Elasticsearch(ELASTICSEARCH_ENDPOINT, api_key=API_KEY)\n",
    "client.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index creation and bulk ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's index some sample data using the bulk API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'errors': False, 'took': 1600, 'items': [{'index': {'_index': 'books', '_id': '1', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'books', '_id': '2', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 0, '_primary_term': 1, 'status': 201}}, {'index': {'_index': 'books', '_id': '3', '_version': 1, 'result': 'created', '_shards': {'total': 1, 'successful': 1, 'failed': 0}, '_seq_no': 1, '_primary_term': 1, 'status': 201}}]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.bulk(\n",
    "    body=[\n",
    "        {\"index\": {\"_index\": \"books\", \"_id\": \"1\"}},\n",
    "        {\n",
    "            \"title\": \"Infinite Jest\",\n",
    "            \"author\": \"David Foster Wallace\",\n",
    "            \"published_on\": datetime(1996, 2, 1),\n",
    "        },\n",
    "        {\"index\": {\"_index\": \"books\", \"_id\": \"2\"}},\n",
    "        {\"title\": \"Ulysses\", \"author\": \"James Joyce\", \"published_on\": datetime(1922, 2, 2)},\n",
    "        {\"index\": {\"_index\": \"books\", \"_id\": \"3\"}},\n",
    "        {\"title\": \"Just Kids\", \"author\": \"Patti Smith\", \"published_on\": datetime(2010, 1, 19)},\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search data and score using BM25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can search data using the Search API and get the relevance score for each result. The relevance score is calculated by default using the BM25 algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.search(index=\"books\", query={\"match\": {\"title\": \"infinite\"}})\n",
    "\n",
    "for hit in response[\"hits\"][\"hits\"]:\n",
    "    print(hit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search data and score using ELSERv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using BM25, we can retrieve the results using ELSERv2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to so that, we need to prepare the index mappings first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index created successfully: {'acknowledged': True, 'shards_acknowledged': True, 'index': 'books_sparse'}\n"
     ]
    }
   ],
   "source": [
    "es_url = f\"{ELASTICSEARCH_ENDPOINT}/books_sparse\"\n",
    "\n",
    "headers = {\"Authorization\": f\"ApiKey {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "data = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\"sparse_embeddings\": {\"type\": \"sparse_vector\"}, \"title\": {\"type\": \"text\"}}\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.put(es_url, headers=headers, json=data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"Index created successfully: {response.json()}\")\n",
    "else:\n",
    "    print(f\"Error when creating the index: {response.status_code}\")\n",
    "    print(f\"Error details: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's generate the text embeddings using an ingest pipeline with an inference processor. The inference processor will use ELSERv2 inference to compute the text embeddings.\n",
    "\n",
    "This step requires ELSERv2 to be downloaded and deployed. We have done it manually in the UI, though this process can also be automated. The model deployment is optimized for ingesting purposes. Additionally, we will have another deployment optimized for search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the ingest pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingest pipeline successfully created: {'acknowledged': True}\n"
     ]
    }
   ],
   "source": [
    "es_url = f\"{ELASTICSEARCH_ENDPOINT}/_ingest/pipeline/generate-elserv2-embeddings-pipeline\"\n",
    "\n",
    "headers = {\"Authorization\": f\"ApiKey {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "data = {\n",
    "    \"description\": \"Generates text embeddings using ELSERv2\",\n",
    "    \"processors\": [\n",
    "        {\n",
    "            \"inference\": {\n",
    "                \"model_id\": \".elser_model_2_linux-x86_64_ingest\",\n",
    "                \"input_output\": [{\"input_field\": \"title\", \"output_field\": \"sparse_embeddings\"}],\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "response = requests.put(es_url, headers=headers, json=data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"Ingest pipeline successfully created: {response.json()}\")\n",
    "else:\n",
    "    print(f\"Error when creating the ingesting pipeline: {response.status_code}\")\n",
    "    print(f\"Error details: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's reindex our books *index* to compute the embeddings for the *title* field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reindex completed successfully: {'took': 706, 'timed_out': False, 'total': 3, 'updated': 0, 'created': 3, 'deleted': 0, 'batches': 1, 'version_conflicts': 0, 'noops': 0, 'retries': {'bulk': 0, 'search': 0}, 'throttled_millis': 0, 'requests_per_second': -1.0, 'throttled_until_millis': 0, 'failures': []}\n"
     ]
    }
   ],
   "source": [
    "es_url = f\"{ELASTICSEARCH_ENDPOINT}/_reindex?wait_for_completion=true\"\n",
    "\n",
    "headers = {\"Authorization\": f\"ApiKey {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"source\": {\n",
    "        \"index\": \"books\",\n",
    "        \"size\": 50,  # batch size for reindexing, the smaller, the quicker\n",
    "    },\n",
    "    \"dest\": {\"index\": \"books_sparse\", \"pipeline\": \"generate-elserv2-embeddings-pipeline\"},\n",
    "}\n",
    "\n",
    "response = requests.post(es_url, headers=headers, json=data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"Reindex completed successfully: {response.json()}\")\n",
    "else:\n",
    "    print(f\"Failed to complete reindexing operation. Status code: {response.status_code}\")\n",
    "    print(f\"Details: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once this data is ingested, we can perform semantic search with ELSERv2 as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query executed successfully: {'took': 35, 'timed_out': False, '_shards': {'total': 3, 'successful': 3, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 3, 'relation': 'eq'}, 'max_score': 2.5879898, 'hits': [{'_index': 'books_sparse', '_id': '1', '_score': 2.5879898, '_source': {'published_on': '1996-02-01T00:00:00', 'sparse_embeddings': {'voice': 0.06321447, 'magic': 0.040825274, 'utter': 0.9487267, 'crowd': 0.015823865, 'pun': 0.2428866, 'ego': 0.0419161, 'anger': 0.68023884, 'improvisation': 0.15309939, 'character': 0.28845063, 'humor': 1.0575207, 'crush': 0.16111338, 'jam': 0.35862505, 'lust': 0.12904637, 'silence': 0.3605276, 'because': 0.120862685, 'fear': 0.12770632, 'song': 0.29209006, 'always': 0.18514793, 'audience': 0.03697875, 'chaos': 0.26750943, 'maxim': 0.3806816, 'ritual': 0.11960416, 'comedy': 0.23235129, 'parody': 0.40718827, '(': 0.12757999, 'protest': 0.15314254, 'animation': 0.26009154, 'rude': 0.49948692, 'distraction': 0.26121494, 'je': 2.5981421, 'math': 0.37924945, 'word': 0.0026837306, 'laughter': 0.41083312, 'infinite': 2.8015947, 'bot': 0.76810795, 'technique': 0.05137294, 'endless': 2.0180466, 'combat': 0.042242188, 'inspiration': 0.30948025, 'pure': 0.22714612, 'error': 0.19188558, 'illusion': 0.82825136, 'nonsense': 0.7238791, 'riddle': 0.33683446, '##st': 2.1671968, 'poem': 0.38176566, 'vulgar': 0.1256579, 'mixture': 0.10195448, 'patience': 0.09295728, 'paradox': 0.4715613, 'demon': 0.060616206, 'savage': 0.09029574, '##ism': 0.21932453, 'poetry': 0.19109397, 'cartoon': 0.20279089, 'unlimited': 1.1926, 'slang': 0.58001494, 'joke': 0.87609327, 'monster': 0.29257977, 'puppet': 0.033631478, 'eternal': 0.026506413, '##ster': 0.65129614, 'torture': 0.06825323, 'truth': 0.06636751, 'speech': 0.18305129, 'infinity': 0.60760784, 'threat': 0.047667105, 'censorship': 0.33145526, 'god': 0.4653259}, 'model_id': '.elser_model_2_linux-x86_64_ingest', 'title': 'Infinite Jest', 'author': 'David Foster Wallace'}}, {'_index': 'books_sparse', '_id': '3', '_score': 0.46240202, '_source': {'published_on': '2010-01-19T00:00:00', 'sparse_embeddings': {'love': 0.1234755, 'education': 0.19980352, 'young': 0.46910143, 'everyone': 0.13189663, 'innocent': 0.11265962, 'kid': 1.1400636, 'barney': 0.09547806, 'nur': 0.20794998, 'pure': 0.11318722, 'todd': 0.8718226, 'people': 0.15156175, 'content': 0.12227596, 'youth': 0.06826124, 'alone': 0.4616983, 'karen': 0.13335232, 'children': 1.3005801, 'school': 0.24960397, 'baby': 0.57021946, 'only': 0.39567998, 'family': 0.08405333, 'just': 2.5935373, 'simply': 0.66766113, 'kids': 2.2753768, 'child': 0.7375963}, 'model_id': '.elser_model_2_linux-x86_64_ingest', 'title': 'Just Kids', 'author': 'Patti Smith'}}, {'_index': 'books_sparse', '_id': '2', '_score': 0.30372357, '_source': {'published_on': '1922-02-02T00:00:00', 'sparse_embeddings': {'gene': 0.22493838, 'irish': 0.30478546, 'barry': 0.11698661, 'hero': 0.122284405, 'ulysses': 2.9737806, 'marvel': 0.7089274, 'poem': 0.4828344, 'award': 0.21844034, 'genus': 0.22292504, 'john': 0.24082948, 'oliver': 0.024550807, 'grant': 0.6387115, 'joyce': 0.38003016, 'novel': 0.52116615}, 'model_id': '.elser_model_2_linux-x86_64_ingest', 'title': 'Ulysses', 'author': 'James Joyce'}}]}}\n",
      "Most relevant retrieved `title`: Infinite Jest\n"
     ]
    }
   ],
   "source": [
    "es_url = f\"{ELASTICSEARCH_ENDPOINT}/books_sparse/_search\"\n",
    "\n",
    "\n",
    "headers = {\"Authorization\": f\"ApiKey {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "data = {\n",
    "    \"query\": {\n",
    "        \"sparse_vector\": {\n",
    "            \"field\": \"sparse_embeddings\",\n",
    "            \"inference_id\": \".elser_model_2_linux-x86_64_search\",\n",
    "            \"query\": \"boundless\",\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = requests.get(es_url, headers=headers, json=data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(f\"Search query executed successfully: {response.json()}\")\n",
    "    print(\n",
    "        f\"Most relevant retrieved `title`: {response.json()['hits']['hits'][0]['_source']['title']}\"\n",
    "    )\n",
    "else:\n",
    "    print(f\"Failed to execute search query. Status code: {response.status_code}\")\n",
    "    print(f\"Details: {response.text}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
